episode_lengths:
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
- 500
episode_rewards:
- 13.085782
- -6.7
- 19.487341
- 9.801352
- -5.5
- -5.7
- 7.265093
- -5.7
- 1.312384
- -6.5
- -0.859337
- -3.41074
- 39.375788
- 67.881357
- 2.257035
- -2.082288
- -5.0
- 0.628272
- 6.446748
- -5.2
- 20.332207
- -5.0
- 29.40126
- -0.867243
- 37.305386
- -5.0
- 200.102845
- -5.0
- 212.295533
- 232.440567
- -5.0
- -5.0
- 188.326008
- 170.265862
- -5.0
- 231.281233
- -5.0
- -5.0
- 169.901439
- -5.0
- -5.0
- -5.0
- -5.0
- 262.032022
- -5.0
- -5.0
- -5.0
- 170.146568
- -3.352633
- -5.0
- -5.0
- -5.0
- -5.0
- 107.21367
- -5.0
- -1.997762
- -0.022127
- -5.0
- -5.0
- 2.890788
- 8.789466
- 3.843239
- 7.705637
- 232.527125
- -5.0
- 146.752971
- 168.499312
- 23.86922
- 208.200547
- 261.99496
- 261.99497
- -5.0
- -5.0
- 2.03198
- 64.52551
- -5.0
- -5.0
- -5.0
- -5.0
- -5.0
- -5.0
- 103.286521
- 2.007562
- -5.0
- -3.434379
- 9.011904
- 20.395457
- 2.561919
- -5.0
- -2.848026
- -5.0
- 47.412171
- 65.721204
- 66.39058
- 7.848148
- -1.025315
- 49.330179
- -2.474142
- 4.918302
- 27.830891
episodes_completed: 100
experiment: baseline_ppo
mean_episode_length: 500.0
mean_last_10_reward: 26.0952018
mean_reward: 37.662523230000005
target_object: Microwave
timestamps: '20250429_205221'
total_timesteps: 50000
training_duration_seconds: 1403.6716539859772
